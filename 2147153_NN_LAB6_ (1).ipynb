{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of MLP and RBF Network - Single hidden layer\n",
        "1. Build a BPN classifier for any kaggle dataset.\n",
        "2. Build an RBF classifier for the same dataset and compare the results."
      ],
      "metadata": {
        "id": "acnurRJUwgsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagation is a widely used algorithm for training feedforward neural networks. It computes the gradient of the loss function with respect to the network weights and is very efficient, rather than naively directly computing the gradient with respect to each individual weight"
      ],
      "metadata": {
        "id": "101AtabzAbWl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cS45Dl1OArln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " loading the database"
      ],
      "metadata": {
        "id": "sgoGZI1z8YuP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWIUfO6z95YQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "0d93d908-c647-4869-d9f6-08ab183b9a5d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c7b7a765a236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"duke-breast-cancer.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Database raw shape (%s,%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: duke-breast-cancer.txt not found."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "db = np.loadtxt(\"duke-breast-cancer.txt\")\n",
        "print(\"Database raw shape (%s,%s)\" % np.shape(db))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting the dataset into training 90% and testing 10% so that the network can train itslef better."
      ],
      "metadata": {
        "id": "XlWyqOaD8nHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(db)\n",
        "y = db[:, 0]\n",
        "x = np.delete(db, [0], axis=1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "print(np.shape(x_train),np.shape(x_test))"
      ],
      "metadata": {
        "id": "PLi0a_Qi73CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the hidden layer vector, weight's matrix, output layer vector and the hidden weight's matrix."
      ],
      "metadata": {
        "id": "wGSWITNy81kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer = np.zeros(72)\n",
        "weights = np.random.random((len(x[0]), 72))\n",
        "output_layer = np.zeros(2)\n",
        "hidden_weights = np.random.random((72, 2))"
      ],
      "metadata": {
        "id": "qo4vpgu175Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Sum function"
      ],
      "metadata": {
        "id": "nUtL3sZd87J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_function(weights, index_locked_col, x):\n",
        "    result = 0\n",
        "    for i in range(0, len(x)):\n",
        "        result += x[i] * weights[i][index_locked_col]\n",
        "    return result"
      ],
      "metadata": {
        "id": "8grGnKZ877fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the activation function"
      ],
      "metadata": {
        "id": "yLXLwpEA9Bh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activate_layer(layer, weights, x):\n",
        "    for i in range(0, len(layer)):\n",
        "        layer[i] = 1.7159 * np.tanh(2.0 * sum_function(weights, i, x) / 3.0)"
      ],
      "metadata": {
        "id": "0asjM6kr7-Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Softmax function"
      ],
      "metadata": {
        "id": "_OC84bsW9FB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def soft_max(layer):\n",
        "    soft_max_output_layer = np.zeros(len(layer))\n",
        "    for i in range(0, len(layer)):\n",
        "        denominator = 0\n",
        "        for j in range(0, len(layer)):\n",
        "            denominator += np.exp(layer[j] - np.max(layer))\n",
        "        soft_max_output_layer[i] = np.exp(layer[i] - np.max(layer)) / denominator\n",
        "    return soft_max_output_layer"
      ],
      "metadata": {
        "id": "KW4bzqj38A39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recalculating the weights function"
      ],
      "metadata": {
        "id": "BZbFXNzP9KJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recalculate_weights(learning_rate, weights, gradient, activation):\n",
        "    for i in range(0, len(weights)):\n",
        "        for j in range(0, len(weights[i])):\n",
        "            weights[i][j] = (learning_rate * gradient[j] * activation[i]) + weights[i][j]"
      ],
      "metadata": {
        "id": "wt1aW3ir8C3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Back propagation function "
      ],
      "metadata": {
        "id": "S-ibk5w69RSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def back_propagation(hidden_layer, output_layer, one_hot_encoding, learning_rate, x):\n",
        "    output_derivative = np.zeros(2)\n",
        "    output_gradient = np.zeros(2)\n",
        "    for i in range(0, len(output_layer)):\n",
        "        output_derivative[i] = (1.0 - output_layer[i]) * output_layer[i]\n",
        "    for i in range(0, len(output_layer)):\n",
        "        output_gradient[i] = output_derivative[i] * (one_hot_encoding[i] - output_layer[i])\n",
        "    hidden_derivative = np.zeros(72)\n",
        "    hidden_gradient = np.zeros(72)\n",
        "    for i in range(0, len(hidden_layer)):\n",
        "        hidden_derivative[i] = (1.0 - hidden_layer[i]) * (1.0 + hidden_layer[i])\n",
        "    for i in range(0, len(hidden_layer)):\n",
        "        sum_ = 0\n",
        "        for j in range(0, len(output_gradient)):\n",
        "            sum_ += output_gradient[j] * hidden_weights[i][j]\n",
        "        hidden_gradient[i] = sum_ * hidden_derivative[i]\n",
        "    recalculate_weights(learning_rate, hidden_weights, output_gradient, hidden_layer)\n",
        "    recalculate_weights(learning_rate, weights, hidden_gradient, x)"
      ],
      "metadata": {
        "id": "O2lzkloS8E7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gKVyzLyo9jy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoding = np.zeros((2,2))\n",
        "for i in range(0, len(one_hot_encoding)):\n",
        "    one_hot_encoding[i][i] = 1\n",
        "training_correct_answers = 0\n",
        "for i in range(0, len(x_train)):\n",
        "    activate_layer(hidden_layer, weights, x_train[i])\n",
        "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
        "    output_layer = soft_max(output_layer)\n",
        "    training_correct_answers += 1 if y_train[i] == np.argmax(output_layer) else 0\n",
        "    back_propagation(hidden_layer, output_layer, one_hot_encoding[int(y_train[i])], -1, x_train[i])\n",
        "print(\"MLP Correct answers while learning: %s / %s (Accuracy = %s) on %s database.\" % (training_correct_answers, len(x_train), \n",
        "                                                                                       training_correct_answers/len(x_train),\"Duke breast cancer\"))"
      ],
      "metadata": {
        "id": "n6pxxNdq8ItV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oKD6tWqb9kXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_correct_answers = 0\n",
        "for i in range(0, len(x_test)):\n",
        "    activate_layer(hidden_layer, weights, x_test[i])\n",
        "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
        "    output_layer = soft_max(output_layer)\n",
        "    testing_correct_answers += 1 if y_test[i] == np.argmax(output_layer) else 0\n",
        "print(\"MLP Correct answers while testing: %s / %s (Accuracy = %s) on %s database\" % (testing_correct_answers, len(x_test),\n",
        "                                                                                     testing_correct_answers/len(x_test), \"Duke breast cancer\"))"
      ],
      "metadata": {
        "id": "QQzZBDwz8LAu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}